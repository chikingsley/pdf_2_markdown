import re
from dataclasses import dataclass
from typing import List, Dict, Optional, Tuple
from datetime import datetime
import fitz  # PyMuPDF
from pathlib import Path

@dataclass
class TextBlock:
    text: str
    font_size: Optional[float] = None
    is_bold: bool = False
    is_italic: bool = False
    level: int = 0
    block_type: str = 'body'  # 'title', 'header', 'body', 'code', 'list'

class ContentCleaner:
    def __init__(self):
        # Enhanced noise patterns
        self.noise_patterns = {
            'headers_footers': [
                r'Page \d+ of \d+',
                r'^\s*\d+\s*$',
                r'©.*?\d{4}',
                r'All rights reserved',
                r'Confidential',
                r'Draft',
                r'Internal use only',
                r'Version \d+\.\d+',
                r'Last updated:.*$',
                r'Last modified:.*$',
                r'Document ID:.*$',
                r'Generated by:.*$',
                r'Created:.*$',
                r'Date:.*$',
            ],
            
            'contact_info': [
                r'Email:.*$',
                r'Address:.*$',
                r'Tel:.*$',
                r'Phone:.*$',
                r'Fax:.*$',
                r'Website:.*$',
                r'\b[\w\.-]+@[\w\.-]+\.\w+\b',
                r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',
            ],
            
            'formatting_artifacts': [
                r'_{3,}',
                r'\*{3,}',
                r'-{3,}',
                r'={3,}',
                r'\_{2,}',
                r'\[Type text\]',
                r'\[\s*\]',
                r'\(\s*\)',
                r'<<.*?>>',
            ],
            
            'institutional': [
                r'University of.*$',
                r'Department of.*$',
                r'Faculty of.*$',
                r'School of.*$',
                r'Institute of.*$',
                r'Laboratory of.*$',
            ],
            
            'academic_extras': [
                r'References\s*\n.*?(?=\n\n|\Z)',  # References section
                r'Appendix\s*[A-Z]?\s*\n.*?(?=\n\n|\Z)',  # Appendices
                r'Attribution-.*?(?=\n|$)',  # Attribution lines
                r'CC BY.*?(?=\n|$)',  # Creative Commons licenses
                r'\[[\d,\s-]+\]',  # Citation markers [1] or [1-3]
                r'\((?:19|20)\d{2}[a-z]?\)',  # Year citations
                r'\((?:(?:19|20)\d{2}[a-z]?(?:,\s*)?)+\)',  # Multiple year citations
                r'(?:[A-Z][a-z]+(?:,?\s+(?:et\s+al\.?|[A-Z]\.|\&))?)+\s*\(\d{4}[a-z]?\)',  # Author citations
            ],
            
            'annotations': [
                r'\[.*?\]',  # Square bracket annotations
                r'\{.*?\}',  # Curly bracket annotations
                r'(?m)^\s*\d+\.\s*$',  # Standalone numbers (like page numbers)
            ]
        }

        # Enhanced content detection
        self.content_patterns = {
            'code_block': [
                r'```.*?```',
                r'(?:^|\n)(?:    |\t).*?(?:\n|$)',
                r'(?:^|\n)(?:function|class|def|import|from|var|let|const).*?(?:\n|$)',
            ],
            
            'list_item': [
                r'^\s*[-*•]\s+',
                r'^\s*\d+\.\s+',
                r'^\s*[a-z]\)\s+',
                r'^\s*[ivx]+\.\s+',
            ],
            
            'header': [
                (r'^#{1,6}\s+.*$', lambda m: len(m.group(0).split()[0])),  # Existing markdown headers
                (r'^[A-Z][^a-z\n]{3,}$', 2),  # ALL CAPS headers
                (r'^\d+\.\d*\s+[A-Z]', 2),    # Numbered sections
                (r'^(?:Abstract|Introduction|Background|Methods?|Results?|Discussion|Conclusion|References)\b', 2),
                (r'^(?:Literature Review|Methodology|Analysis|Findings|Implications|Appendix)\b', 2),
            ],
            
            'academic_elements': [
                r'^\*.*?\*$',  # Italicized author names/affiliations
                r'\(.*?\d{4}.*?\)',  # Citations
                r'\[.*?\]',  # Reference markers
            ]
        }

    def clean_pdf(self, pdf_path: Path) -> Dict:
        """Process PDF file into clean markdown"""
        try:
            doc = fitz.open(pdf_path)
            text = ""
            for page in doc:
                text += page.get_text()
            doc.close()
            return self.clean_text(text)
        except Exception as e:
            raise Exception(f"Error processing PDF: {e}")

    def clean_text(self, text: str) -> Dict:
        """Main cleaning method"""
        original_text = text
        metadata = {
            'date': datetime.now().isoformat(),
            'stats': {
                'original_length': len(text),
                'patterns_removed': 0,
                'code_blocks': 0,
                'lists': 0,
                'headers': 0
            }
        }

        # Remove noise patterns
        for category, patterns in self.noise_patterns.items():
            for pattern in patterns:
                cleaned = re.sub(pattern, '', text, flags=re.MULTILINE | re.IGNORECASE)
                if cleaned != text:
                    metadata['stats']['patterns_removed'] += 1
                text = cleaned

        # Process blocks
        blocks = self._split_into_blocks(text)
        processed_blocks = self._process_blocks(blocks, metadata['stats'])
        
        # Generate markdown
        markdown = self._blocks_to_markdown(processed_blocks)
        
        # Final cleanup
        markdown = self._cleanup_markdown(markdown)
        
        metadata['stats']['final_length'] = len(markdown)
        metadata['original_text'] = original_text
        
        return {
            'text': markdown,
            'metadata': metadata
        }

    def _split_into_blocks(self, text: str) -> List[TextBlock]:
        """Split text into logical blocks"""
        lines = text.split('\n')
        blocks = []
        current_block = []
        current_type = 'body'
        
        for line in lines:
            line = line.strip()
            if not line:
                if current_block:
                    blocks.append(TextBlock(
                        text='\n'.join(current_block),
                        block_type=current_type
                    ))
                    current_block = []
                    current_type = 'body'
                continue
            
            # Detect block type
            new_type = self._detect_block_type(line)
            
            # If type changes, create new block
            if new_type != current_type and current_block:
                blocks.append(TextBlock(
                    text='\n'.join(current_block),
                    block_type=current_type
                ))
                current_block = []
            
            current_type = new_type
            current_block.append(line)

        if current_block:
            blocks.append(TextBlock(
                text='\n'.join(current_block),
                block_type=current_type
            ))

        return blocks

    def _detect_block_type(self, line: str) -> str:
        """Detect type of text block"""
        # Check for code block
        for pattern in self.content_patterns['code_block']:
            if re.match(pattern, line):
                return 'code'
        
        # Check for list item
        for pattern in self.content_patterns['list_item']:
            if re.match(pattern, line):
                return 'list'
        
        # Check for header
        for pattern, level in self.content_patterns['header']:
            if isinstance(pattern, str) and re.match(pattern, line):
                return 'header'
        
        return 'body'

    def _process_blocks(self, blocks: List[TextBlock], stats: Dict) -> List[TextBlock]:
        """Process and enhance blocks"""
        processed = []
        
        for block in blocks:
            if block.block_type == 'code':
                stats['code_blocks'] += 1
                # Ensure code blocks are properly formatted
                if not block.text.startswith('```'):
                    block.text = f'```\n{block.text}\n```'
            
            elif block.block_type == 'list':
                stats['lists'] += 1
                # Ensure consistent list formatting
                block.text = re.sub(r'^\s*[-*•]\s+', '- ', block.text)
            
            elif block.block_type == 'header':
                stats['headers'] += 1
                # Ensure proper header formatting
                level = 2  # default level
                for pattern, lvl in self.content_patterns['header']:
                    if isinstance(pattern, str) and re.match(pattern, block.text):
                        level = lvl if isinstance(lvl, int) else lvl(re.match(pattern, block.text))
                        break
                block.text = f'{"#" * level} {block.text.lstrip("#").strip()}'
            
            processed.append(block)
        
        # Apply academic-specific processing
        processed = self._process_academic_structure(processed)
        
        return processed

    def _process_academic_structure(self, blocks: List[TextBlock]) -> List[TextBlock]:
        """Process blocks specifically for academic paper structure"""
        processed = []
        in_abstract = False
        skip_section = False
        
        for block in blocks:
            text = block.text.strip()
            
            # Skip references and appendices sections
            if any(text.lower().startswith(x) for x in ['references', 'appendix', 'appendices']):
                skip_section = True
                continue
            
            if skip_section and block.block_type == 'header':
                skip_section = False
            
            if skip_section:
                continue
            
            # Handle title (usually the first header)
            if not processed and block.block_type == 'header':
                block.level = 1  # Make it H1
                processed.append(block)
                continue
            
            # Handle authors and affiliations
            if len(processed) < 3 and '*' in text:
                processed.append(TextBlock(text=text, block_type='body'))
                continue
                
            # Handle abstract section
            if text.lower() == 'abstract':
                in_abstract = True
                block.level = 2  # Make it H2
                processed.append(block)
                continue
                
            if in_abstract and block.block_type == 'header':
                in_abstract = False
            
            processed.append(block)
        
        return processed

    def _blocks_to_markdown(self, blocks: List[TextBlock]) -> str:
        """Convert blocks to markdown"""
        markdown_lines = []
        
        for block in blocks:
            if block.block_type == 'body':
                # Wrap non-empty body blocks in paragraphs
                if block.text.strip():
                    markdown_lines.append(f"\n{block.text}\n")
            else:
                markdown_lines.append(block.text)
                if block.block_type != 'code':
                    markdown_lines.append('')  # Extra newline after non-code blocks
        
        return '\n'.join(markdown_lines)

    def _cleanup_markdown(self, markdown: str) -> str:
        """Final markdown cleanup with academic paper considerations"""
        # Remove excessive newlines
        markdown = re.sub(r'\n{3,}', '\n\n', markdown)
        
        # Ensure proper spacing around headers
        markdown = re.sub(r'(^|\n)(#+\s.*?)(\n|$)', r'\1\n\2\n', markdown)
        
        # Fix citation spacing
        markdown = re.sub(r'\(\s*(\d{4})\s*\)', r'(\1)', markdown)
        
        # Ensure proper spacing around block quotes
        markdown = re.sub(r'(\n>.*?)(\n(?!>)|\Z)', r'\1\n', markdown)
        
        # Fix list spacing in academic context
        markdown = re.sub(r'(\n- .*?)(\n(?!-)|\Z)', r'\1\n', markdown)
        
        return markdown.strip()

# Create global instance
cleaner = ContentCleaner()